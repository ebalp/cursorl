{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 : Multi-Armed Bandits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('Day1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Using cached https://files.pythonhosted.org/packages/5c/e0/be401c003291b56efc55aeba6a80ab790d3d4cece2778288d65323009420/pip-19.1.1-py2.py3-none-any.whl\n",
      "Installing collected packages: pip\n",
      "  Found existing installation: pip 19.1\n",
      "    Uninstalling pip-19.1:\n",
      "      Successfully uninstalled pip-19.1\n",
      "Successfully installed pip-19.1.1\n",
      "Requirement already satisfied: numpy>=1.16.3 in /Users/marco/anaconda3/envs/synx/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (1.16.3)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /Users/marco/anaconda3/envs/synx/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (1.2.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.3 in /Users/marco/anaconda3/envs/synx/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.0.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/marco/anaconda3/envs/synx/lib/python3.7/site-packages (from matplotlib>=3.0.3->-r requirements.txt (line 3)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/marco/anaconda3/envs/synx/lib/python3.7/site-packages (from matplotlib>=3.0.3->-r requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/marco/anaconda3/envs/synx/lib/python3.7/site-packages (from matplotlib>=3.0.3->-r requirements.txt (line 3)) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/marco/anaconda3/envs/synx/lib/python3.7/site-packages (from matplotlib>=3.0.3->-r requirements.txt (line 3)) (2.8.0)\n",
      "Requirement already satisfied: six in /Users/marco/anaconda3/envs/synx/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=3.0.3->-r requirements.txt (line 3)) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /Users/marco/anaconda3/envs/synx/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=3.0.3->-r requirements.txt (line 3)) (41.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "- Multi-armed Bandits\n",
    "- Epsilon-Greedy\n",
    "- Upper Confidence Bound (UCB)\n",
    "- Bayesian UCB\n",
    "- Thompson Sampling\n",
    "- Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-armed Bandits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the `BernoulliBandit` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Day1.bandits import BernoulliBandit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantate an object of `BernoulliBandit` called `mab`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of bandits\n",
    "n = 4\n",
    "\n",
    "# List of probabilities of giving reward for each bandit\n",
    "probas = [0.6, 0.2, 0.3, 0.55]\n",
    "\n",
    "# Object instantiation\n",
    "mab = BernoulliBandit(n, probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object `mab` has only one method `generate_reward` which takes one input: the number of the arm being pulled. \n",
    "\n",
    "Let's generate some rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n):\n",
    "    print('Sampled reward for {} bandit: {}'.format(i, mab.generate_reward(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epsilon-Greedy Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Day1.solvers import EpsilonGreedy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate an `EpsilonGreedy` strategy by providing a `BernoulliBandit` object and a number $\\epsilon \\in [0,1]$ which is the probability of exploration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epsilon value\n",
    "epsilon = 0.1\n",
    "\n",
    "# Object instantiation\n",
    "egreedy = EpsilonGreedy(mab, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object `egreedy` has the method `run` which takes as input an integer `num_steps` and does the following loop for `num_steps` times:\n",
    "- Select an arm according to the strategy. That is, with probability $\\epsilon$ select a random arn and with probability $1 - \\epsilon$ select the arm with the best sampled mean reward.\n",
    "- Observe the reward.\n",
    "- Update the strategy. That is, update the observed reward frequency for each arm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us run the strategy for a number of rounds and plot the regret. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rounds\n",
    "n = 10000\n",
    "\n",
    "# Run for n rounds\n",
    "egreedy.run(n)\n",
    "\n",
    "# Plot cumulative regret\n",
    "plt.plot(egreedy.regrets)\n",
    "plt.xlabel('Number of Rounds')\n",
    "plt.ylabel('Cumulative Regret')\n",
    "plt.title('Regret')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upper Confidence Bound (UCB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Day1.solvers import UCB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate an `UCB` strategy by providing a `BernoulliBandit` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object instantiation\n",
    "ucb = UCB(mab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object `ucb` has the method `run` which takes as input an integer `num_steps` and does the following loop for `num_steps` times:\n",
    "- Select an arm according to the strategy. That is, select the greediest action to maximize the upper confidence bound estimated via the Hoeffdingâ€™s inequality.\n",
    "- Observe the reward.\n",
    "- Update the strategy. That is, update the observed reward frequency and the upper confidence bound for each arm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us run the strategy for a number of rounds and plot the regret. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Number of rounds\n",
    "n = 10000\n",
    "\n",
    "# Run for n rounds\n",
    "ucb.run(n)\n",
    "\n",
    "# Plot cumulative regret\n",
    "plt.plot(ucb.regrets)\n",
    "plt.xlabel('Number of Rounds')\n",
    "plt.ylabel('Cumulative Regret')\n",
    "plt.title('Regret')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian UCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Day1.solvers import BayesianUCB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate an `BayesianUCB` strategy by providing a `BernoulliBandit` object, a positive integer `c` and optionally two positive integers `init_a` and `init_b`. `BayesianUCB` makes use of a beta distribution (one for each arm) to model the **belief distribution** for the probability of distributing reward. This belief probability is parametrized by values `a` and `b` which are initialized to `init_a=1` and `init_b=1` (this codes for a uniform distribution on the interval $[0,1]$). If additinal information is known of the belief distribution of the arms it can be provided to the solver by changing these default values. The integer `c` establishes how many standard deviations to consider as upper confidence bound. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object instantiation\n",
    "b_ucb = BayesianUCB(mab, c=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object `b_ucb` has the method `run` which takes as input an integer `num_steps`. The solver does the following loop for `num_steps` times:\n",
    "\n",
    "- Select an arm according to the strategy. That is, select the greediest action to maximize the upper confidence bound estimated using `c` standard deviations of the belief distribution.\n",
    "- Observe the reward.\n",
    "- Update the strategy. That is, update the parameters `a` and `b` of the belief distribution of each arm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us run the strategy for a number of rounds and plot the regret. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Number of rounds\n",
    "n = 10000\n",
    "\n",
    "# Run for n rounds\n",
    "b_ucb.run(n)\n",
    "\n",
    "# Plot cumulative regret\n",
    "plt.plot(b_ucb.regrets)\n",
    "plt.xlabel('Number of Rounds')\n",
    "plt.ylabel('Cumulative Regret')\n",
    "plt.title('Regret')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the probability density function of the beta distribution for each arm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Day1.util import plot_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_beta(b_ucb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thompson Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Day1.solvers import ThompsonSampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate an `ThompsonSampling` strategy by providing a `BernoulliBandit` object, and optionally two positive integers `init_a` and `init_b` that initalise the belief beta distribution for each arm in the same manner as we did for the `BayesianUCB` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object instantiation\n",
    "thompson = ThompsonSampling(mab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object `thompson` has the method `run` which takes as input an integer `num_steps`. The solver does the following loop for `num_steps` times:\n",
    "\n",
    "- Select an arm according to the strategy. That is, we sample from the belief distribution for each arm and select the action that maximizes the sample value.\n",
    "- Observe the reward.\n",
    "- Update the strategy. That is, update the parameters `a` and `b` of the belief distribution of each arm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us run the strategy for a number of rounds and plot the regret. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rounds\n",
    "n = 10000\n",
    "\n",
    "# Run for n rounds\n",
    "thompson.run(n)\n",
    "\n",
    "# Plot cumulative regret\n",
    "plt.plot(b_ucb.regrets)\n",
    "plt.xlabel('Number of Rounds')\n",
    "plt.ylabel('Cumulative Regret')\n",
    "plt.title('Regret')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the pdf of the beta distribution for each arm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_beta(thompson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make some experiments to compare the performance of each of the multi-armed bandit solvers. \n",
    "\n",
    "You may use the following function to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Day1.util import plot_results\n",
    "help(plot_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_results([egreedy, ucb, b_ucb, thompson], \n",
    "             ['Epsilon Greedy', 'UCB', 'Bayesian UCB', 'Thompson Sampling'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "248px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
